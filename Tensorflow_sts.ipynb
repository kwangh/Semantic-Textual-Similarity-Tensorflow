{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "data_path=SICK\n",
      "embedding_dim=300\n",
      "max_length=26\n",
      "save_path=SICK/STS_log\n",
      "use_fp64=False\n",
      "word2vec_norm=embeddings/word2vec_norm.txt\n"
     ]
    }
   ],
   "source": [
    "# Model Hyperparameters\n",
    "flags=tf.flags\n",
    "\n",
    "flags.DEFINE_string('word2vec_norm','embeddings/word2vec_norm.txt','Word2vec file with pre-trained embeddings')\n",
    "flags.DEFINE_string('data_path','SICK','SICK data set path')\n",
    "flags.DEFINE_string('save_path','SICK/STS_log','STS model output directory')\n",
    "flags.DEFINE_integer('embedding_dim',300,'Dimensionality of word embedding')\n",
    "flags.DEFINE_integer('max_length',26,'one sentence max length words which is in dictionary')\n",
    "flags.DEFINE_bool('use_fp64',False,'Train using 64-bit floats instead of 32bit floats')\n",
    "\n",
    "FLAGS=flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print('Parameters:')\n",
    "for attr,value in sorted(FLAGS.__flags.items()):\n",
    "    print('{}={}'.format(attr,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_type():\n",
    "    return tf.float64 if FLAGS.use_fp64 else tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(word2vec_path=None):\n",
    "    if word2vec_path:\n",
    "        print('Load word2vec_norm file {}'.format(word2vec_path))\n",
    "        with open(word2vec_path,'r') as f:\n",
    "            header=f.readline()\n",
    "            vocab_size,layer2_size=map(int,header.split())\n",
    "            # initial matrix with random uniform\n",
    "            init_W=np.random.uniform(-0.25,0.25,(vocab_size,FLAGS.embedding_dim))\n",
    "\n",
    "            print('vocab_size={}'.format(vocab_size))\n",
    "            dictionary=dict()\n",
    "            while True:\n",
    "                line=f.readline()\n",
    "                if not line:break\n",
    "                word=line.split()[0]\n",
    "                dictionary[word]=len(dictionary)\n",
    "                init_W[dictionary[word]]=np.array(line.split()[1:], dtype=np.float32)\n",
    "\n",
    "        return dictionary,init_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def file_to_word_ids(filename,word_to_id):\n",
    "    with open(filename,'r') as f:\n",
    "        f.readline() # remove header\n",
    "        sentences_A=[]\n",
    "        sentencesA_length=[]\n",
    "        sentences_B=[]\n",
    "        sentencesB_length=[]\n",
    "        relatedness_scores=[]\n",
    "        while True:\n",
    "            line=f.readline()\n",
    "            if not line: break\n",
    "            pair_ID=line.split('\\t')[0] # for trial & test\n",
    "            sentence_A=line.split('\\t')[1]\n",
    "            sentence_B=line.split('\\t')[2]\n",
    "            relatedness_score=line.split('\\t')[3]    \n",
    "            _=[word_to_id[word] for word in sentence_A.split() if word in word_to_id]\n",
    "            _+=[0]*(FLAGS.max_length-len(_))\n",
    "            sentences_A.append(_)\n",
    "            sentencesA_length.append(len(_))\n",
    "            _=[word_to_id[word] for word in sentence_B.split() if word in word_to_id]\n",
    "            _+=[0]*(FLAGS.max_length-len(_))\n",
    "            sentences_B.append(_)\n",
    "            sentencesB_length.append(len(_))\n",
    "            relatedness_scores.append((float(relatedness_score)-1)/4)\n",
    "    assert len(sentences_A)==len(sentencesA_length)==len(sentences_B)==len(sentencesB_length)==len(relatedness_scores)\n",
    "    return STSInput(sentences_A,sentencesA_length,sentences_B,sentencesB_length,relatedness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class STSInput(object):\n",
    "    def __init__(self,sentences_A,sentencesA_length,sentences_B,sentencesB_length,relatedness_scores):\n",
    "        self.sentences_A=sentences_A\n",
    "        self.sentencesA_length=sentencesA_length\n",
    "        self.sentences_B=sentences_B\n",
    "        self.sentencesB_length=sentencesB_length\n",
    "        self.relatedness_scores=relatedness_scores\n",
    "    \n",
    "    def sentences_A(self):\n",
    "        return self.sentences_A\n",
    "    \n",
    "    def sentencesA_length(self):\n",
    "        return self.sentencesA_length\n",
    "    \n",
    "    def sentences_B(self):\n",
    "        return self.sentences_B\n",
    "    \n",
    "    def sentencesA_length(self):\n",
    "        return self.sentencesB_length\n",
    "    \n",
    "    def relatedness_scores(self):\n",
    "        return self.relatedness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load word2vec_norm file embeddings/word2vec_norm.txt\n",
      "vocab_size=2378\n"
     ]
    }
   ],
   "source": [
    "train_path=os.path.join(FLAGS.data_path,'SICK_train.txt')\n",
    "valid_path=os.path.join(FLAGS.data_path,'SICK_trial.txt')\n",
    "test_path=os.path.join(FLAGS.data_path,'SICK_test_annotated.txt')\n",
    "\n",
    "dictionary,init_W=build_vocab(FLAGS.word2vec_norm)\n",
    "train_data=file_to_word_ids(train_path,dictionary)\n",
    "valid_data=file_to_word_ids(valid_path,dictionary)\n",
    "test_data=file_to_word_ids(test_path,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(start,end,input):\n",
    "    inputs_A=input.sentences_A[start:end]\n",
    "    inputsA_length=input.sentencesA_length[start:end]\n",
    "    inputs_B=input.sentences_B[start:end]\n",
    "    inputsB_length=input.sentencesB_length[start:end]\n",
    "    labels=np.reshape(input.relatedness_scores[start:end],(len(range(start,end)),1))\n",
    "    return inputs_A,inputsA_length,inputs_B,inputsB_length,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    learning_rate=1\n",
    "    max_grad_norm=5\n",
    "    #num_layers=2\n",
    "    #hidden_size=100\n",
    "    keep_prob=1.0\n",
    "    #lr_decay=0.5\n",
    "    batch_size=20\n",
    "    max_epoch=30\n",
    "    \n",
    "config=Config()\n",
    "test_config=Config()\n",
    "test_config.batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(input_,input_length,dropout_):\n",
    "    rnn_cell=tf.nn.rnn_cell.LSTMCell(num_units=50,state_is_tuple=True)\n",
    "    rnn_cell=tf.nn.rnn_cell.DropoutWrapper(rnn_cell,output_keep_prob=dropout_)\n",
    "    #rnn_cell=tf.nn.rnn_cell.MultiRNNCell([rnn_cell]*50,state_is_tuple=True)\n",
    "        \n",
    "    outputs,last_states=tf.nn.dynamic_rnn(\n",
    "        cell=rnn_cell,\n",
    "        dtype=data_type(),\n",
    "        sequence_length=input_length,\n",
    "        inputs=input_\n",
    "    )\n",
    "    return outputs,last_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_A=tf.placeholder(tf.int32,shape=([None,FLAGS.max_length]),name='sentences_A')\n",
    "sentencesA_length=tf.placeholder(tf.int32,shape=([None]),name='sentencesA_length')\n",
    "sentences_B=tf.placeholder(tf.int32,shape=([None,FLAGS.max_length]),name='sentences_B')\n",
    "sentencesB_length=tf.placeholder(tf.int32,shape=([None]),name='sentencesB_length')\n",
    "labels=tf.placeholder(tf.float32,shape=([None,1]),name='relatedness_score_label')\n",
    "dropout_f=tf.placeholder(tf.float32)\n",
    "W=tf.Variable(tf.constant(0.0,shape=[len(dictionary),FLAGS.embedding_dim]),trainable=False,name='W')\n",
    "embedding_placeholder=tf.placeholder(data_type(),[len(dictionary),FLAGS.embedding_dim])\n",
    "embedding_init=W.assign(embedding_placeholder)\n",
    "\n",
    "sentences_A_emb=tf.nn.embedding_lookup(params=embedding_init,ids=sentences_A)\n",
    "sentences_B_emb=tf.nn.embedding_lookup(params=embedding_init,ids=sentences_B)\n",
    "\n",
    "## lstm codes\n",
    "#lstm_cell=tf.nn.rnn_cell.BasicLSTMCell(num_units=config.hidden_size,forget_bias=0.0,state_is_tuple=True)\n",
    "#if is_training and config.keep_prob<1:\n",
    "#    lstm_cell=tf.nn.rnn_cell.DropoutWrapper(lstm_cell,output_keep_prob=config.keep_prob)\n",
    "\n",
    "with tf.variable_scope('siamese') as scope:\n",
    "    outputs_A,last_states_A=build_model(sentences_A_emb,sentencesA_length,dropout_f)\n",
    "    scope.reuse_variables()\n",
    "    outputs_B,last_states_B=build_model(sentences_B_emb,sentencesB_length,dropout_f)\n",
    "    \n",
    "#outputs_A=tf.transpose(outputs_A,[1,0,2])\n",
    "#last_A=tf.gather(outputs_A,int(outputs_A.get_shape()[0])-1)\n",
    "last_A=tf.transpose(outputs_A,[1,0,2])[-1]\n",
    "#outputs_B=tf.transpose(outputs_B,[1,0,2])\n",
    "#last_B=tf.gather(outputs_B,int(outputs_B.get_shape()[0])-1)\n",
    "last_B=tf.transpose(outputs_B,[1,0,2])[-1]\n",
    "#concat_outputs=tf.concat(1,[last_A,last_B])\n",
    "#fully_connected = tf.contrib.layers.fully_connected(concat_outputs,num_outputs=1,activation_fn=tf.tanh)\n",
    "#prediction=4*tf.exp(-tf.abs(last_A-last_B))+1\n",
    "prediction=tf.exp(tf.mul(-1.0,tf.reduce_mean(tf.abs(tf.sub(last_A,last_B)),1)))\n",
    "\n",
    "cost=tf.reduce_mean(tf.square(tf.sub(prediction, labels)))\n",
    "optimizer=tf.train.AdadeltaOptimizer(learning_rate=config.learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdadeltaOptimizer(learning_rate=config.learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 cost: 0.196330890059\n",
      "Epoch 199 cost: 0.128718793392\n",
      "Epoch 299 cost: 0.112614035606\n",
      "Epoch 399 cost: 0.106197945774\n",
      "Epoch 499 cost: 0.102252840996\n",
      "Epoch 599 cost: 0.100890211761\n",
      "Epoch 699 cost: 0.0991185232997\n",
      "Epoch 799 cost: 0.0978290811181\n",
      "Epoch 899 cost: 0.0967794507742\n",
      "Epoch 999 cost: 0.0985529944301\n",
      "Epoch 1099 cost: 0.0910010486841\n",
      "Epoch 1199 cost: 0.0885689780116\n",
      "Epoch 1299 cost: 0.0855084434152\n",
      "Epoch 1399 cost: 0.0832052379847\n",
      "Epoch 1499 cost: 0.080598577857\n",
      "Epoch 1599 cost: 0.0792081356049\n",
      "Epoch 1699 cost: 0.0769901350141\n",
      "Epoch 1799 cost: 0.0749821662903\n",
      "Epoch 1899 cost: 0.0750486701727\n",
      "Epoch 1999 cost: 0.0742984414101\n",
      "Epoch 2099 cost: 0.0732833296061\n",
      "Epoch 2199 cost: 0.0721606165171\n",
      "Epoch 2299 cost: 0.0733586326241\n",
      "Epoch 2399 cost: 0.0712243914604\n",
      "Epoch 2499 cost: 0.070658646524\n",
      "Epoch 2599 cost: 0.0703594908118\n",
      "Epoch 2699 cost: 0.0703352838755\n",
      "Epoch 2799 cost: 0.0704281404614\n",
      "Epoch 2899 cost: 0.0729647502303\n",
      "Epoch 2999 cost: 0.0715019479394\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    #total_batch=int(len(train_data.sentences_A)/config.batch_size)\n",
    "    #print('Total batch size: {}'.format(total_batch))\n",
    "    for epoch in range(3001):\n",
    "        _,train_cost,train_predict=sess.run([optimizer,cost,prediction],feed_dict={\n",
    "                sentences_A:train_data.sentences_A,\n",
    "                sentencesA_length:train_data.sentencesA_length,\n",
    "                sentences_B:train_data.sentences_B,\n",
    "                sentencesB_length:train_data.sentencesB_length,\n",
    "                labels:np.reshape(train_data.relatedness_scores,(len(train_data.relatedness_scores),1)),\n",
    "                dropout_f:config.keep_prob,\n",
    "                embedding_placeholder:init_W\n",
    "            })\n",
    "        if (epoch+1)%100==0:\n",
    "            print('Epoch {} cost: {}'.format(epoch,train_cost))\n",
    "            \n",
    "    valid_cost,valid_predict=sess.run([cost,prediction],feed_dict={\n",
    "        sentences_A:valid_data.sentences_A,\n",
    "        sentencesA_length:valid_data.sentencesA_length,\n",
    "        sentences_B:valid_data.sentences_B,\n",
    "        sentencesB_length:valid_data.sentencesB_length,\n",
    "        labels:np.reshape(valid_data.relatedness_scores,(len(valid_data.relatedness_scores),1)),\n",
    "        embedding_placeholder:init_W,\n",
    "        dropout_f:1.0\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0744059\n"
     ]
    }
   ],
   "source": [
    "print(valid_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65472889,  0.62773985,  0.63553274,  0.61985922,  0.65749645,\n",
       "        0.59526312,  0.60881442,  0.64743781,  0.60089278,  0.60560602,\n",
       "        0.58317351,  0.60160404,  0.94305998,  0.62173247,  0.62364352,\n",
       "        0.53023529,  0.72813851,  0.61526239,  0.62668103,  0.61317545,\n",
       "        0.62274402,  0.97923708,  0.58127093,  0.76340103,  0.81697023,\n",
       "        0.54462194,  0.88787103,  0.63298553,  0.55738062,  0.78021127,\n",
       "        0.61033678,  0.67247957,  0.572411  ,  0.66396266,  0.88944554,\n",
       "        0.62403977,  0.66209328,  0.57218558,  0.57088244,  0.55826885,\n",
       "        0.6160937 ,  0.64982164,  0.54442036,  0.65664655,  0.48274091,\n",
       "        0.64345247,  0.67189705,  0.64539301,  0.57586831,  0.67434341,\n",
       "        0.71495676,  0.69430733,  0.8388167 ,  0.64249885,  0.61200064,\n",
       "        0.61254108,  0.76130354,  0.63075459,  0.94995099,  0.80424619,\n",
       "        0.71876734,  0.65588135,  0.83130759,  0.65730298,  0.88016921,\n",
       "        0.63044465,  0.61255813,  0.93140352,  0.67743707,  0.62877023,\n",
       "        0.56493497,  0.6230073 ,  0.56965792,  0.66816467,  0.79211575,\n",
       "        0.66049832,  0.77081728,  0.65105367,  0.6225251 ,  0.97152025,\n",
       "        0.61102796,  0.62991941,  0.66573989,  0.59083891,  0.57756555,\n",
       "        0.6237877 ,  0.62394369,  0.5872066 ,  0.63580739,  0.89796239,\n",
       "        0.62030274,  0.62318122,  0.55009449,  0.5960179 ,  0.53522497,\n",
       "        0.53966433,  0.56236875,  0.57750851,  0.77403992,  0.52660102,\n",
       "        0.6253069 ,  0.6327123 ,  0.60830605,  0.95522976,  0.62891001,\n",
       "        0.64056784,  0.6040507 ,  0.59417331,  0.60223651,  0.81462729,\n",
       "        0.58337915,  0.96952063,  0.64446437,  0.74247342,  0.57302451,\n",
       "        0.57968682,  0.66812485,  0.64836383,  0.56271851,  0.67381734,\n",
       "        0.60404003,  0.66089106,  0.65434968,  0.73736262,  0.53804094,\n",
       "        0.66000336,  0.51784432,  0.82565022,  0.64779317,  0.65316105,\n",
       "        0.7014243 ,  0.59348404,  0.65974921,  0.57085878,  0.68715554,\n",
       "        0.77947563,  0.60393995,  0.55559486,  0.61214417,  0.72703999,\n",
       "        0.78881556,  0.64483839,  0.63263559,  0.59052074,  0.61237794,\n",
       "        0.6299088 ,  0.5838958 ,  0.61269695,  0.64706415,  0.88009107,\n",
       "        0.69983864,  0.57141912,  0.63007534,  0.60003126,  0.64198011,\n",
       "        0.65514493,  0.61333948,  0.54261804,  0.80891824,  0.61978161,\n",
       "        0.61851168,  0.52603525,  0.61027211,  0.8343544 ,  0.59483576,\n",
       "        0.64546341,  0.72529155,  0.60973865,  0.72944832,  0.54541355,\n",
       "        0.56661946,  0.59970862,  0.65573448,  0.53457552,  0.67061067,\n",
       "        0.52245432,  0.6384387 ,  0.74774629,  0.60398346,  0.61747384,\n",
       "        0.61647969,  0.58141607,  0.80252492,  0.63205028,  0.86043268,\n",
       "        0.89219934,  0.59949058,  0.65806949,  0.84199214,  0.6497283 ,\n",
       "        0.66933221,  0.60633838,  0.67777658,  0.64640176,  0.63137728,\n",
       "        0.68462515,  0.55421847,  0.60570663,  0.61384666,  0.68643486,\n",
       "        0.7286039 ,  0.64162713,  0.70635337,  0.63147366,  0.77526802,\n",
       "        0.62790751,  0.6536299 ,  0.61613226,  0.59832799,  0.56972224,\n",
       "        0.58122957,  0.57069808,  0.79414105,  0.68242121,  0.59622717,\n",
       "        0.58667672,  0.62704086,  0.94043756,  0.67963922,  0.58662355,\n",
       "        0.64825022,  0.6616022 ,  0.70162845,  0.59660488,  0.61118633,\n",
       "        0.58444339,  0.63791668,  0.61890942,  0.57367361,  0.85281062,\n",
       "        0.64247096,  0.66425639,  0.69166654,  0.9634009 ,  0.92043662,\n",
       "        0.56326801,  0.82057124,  0.65168399,  0.7308898 ,  0.55958515,\n",
       "        0.61023819,  0.61397725,  0.57915354,  0.66527361,  0.60804778,\n",
       "        0.65542132,  0.7814604 ,  0.54732245,  0.65173137,  0.6159122 ,\n",
       "        0.54223436,  0.63748282,  0.56645179,  0.62026829,  0.67219824,\n",
       "        0.57145429,  0.54609597,  0.6518209 ,  0.61411929,  0.71716857,\n",
       "        0.55146319,  0.81581849,  0.59165841,  0.57046616,  0.65586919,\n",
       "        0.66657579,  0.74065226,  0.60518986,  0.58820242,  0.72739697,\n",
       "        0.6386469 ,  0.66530681,  0.6158092 ,  0.69944876,  0.53720605,\n",
       "        0.73871225,  0.60616678,  0.60619092,  0.60193455,  0.65511078,\n",
       "        0.57629472,  0.63074058,  0.65858305,  0.88007522,  0.58084017,\n",
       "        0.64386261,  0.61913025,  0.70938993,  0.9829008 ,  0.61648613,\n",
       "        0.64959627,  0.56465328,  0.79973149,  0.67931044,  0.97004133,\n",
       "        0.64934117,  0.55990499,  0.63394141,  0.59976953,  0.61822385,\n",
       "        0.68810236,  0.60575211,  0.60382038,  0.52037185,  0.84073544,\n",
       "        0.57345361,  0.62535852,  0.62195057,  0.68023282,  0.67040259,\n",
       "        0.63674212,  0.67117226,  0.65534753,  0.63757485,  0.7450549 ,\n",
       "        0.611974  ,  0.64408511,  0.62213898,  0.82149273,  0.55254954,\n",
       "        0.63000321,  0.63337272,  0.61628389,  0.87963039,  0.59869105,\n",
       "        0.60078192,  0.67784399,  0.92261463,  0.56826717,  0.60013902,\n",
       "        0.65898937,  0.66329873,  0.60159934,  0.61583507,  0.60183233,\n",
       "        0.59340894,  0.6469515 ,  0.57685488,  0.64825249,  0.87462658,\n",
       "        0.44568244,  0.64157933,  0.56662089,  0.60689247,  0.57730812,\n",
       "        0.89894003,  0.5440318 ,  0.78534693,  0.65372825,  0.78318655,\n",
       "        0.76282167,  0.9429813 ,  0.65727115,  0.63324213,  0.96407789,\n",
       "        0.630638  ,  0.63065088,  0.50979197,  0.53111422,  0.57198793,\n",
       "        0.63713825,  0.51595193,  0.80680317,  0.55326647,  0.66766012,\n",
       "        0.62151515,  0.64130133,  0.68202257,  0.624578  ,  0.64143866,\n",
       "        0.59708661,  0.7656821 ,  0.6105355 ,  0.9938103 ,  0.56381851,\n",
       "        0.55709273,  0.50520581,  0.600941  ,  0.74081957,  0.59554887,\n",
       "        0.60773134,  0.52239627,  0.63265699,  0.61393988,  0.64114338,\n",
       "        0.54727489,  0.57519716,  0.63732141,  0.63603622,  0.63647038,\n",
       "        0.56841278,  0.62747842,  0.85985136,  0.89229625,  0.65233272,\n",
       "        0.56596822,  0.92689264,  0.64451444,  0.58958989,  0.53477991,\n",
       "        0.68813789,  0.6414336 ,  0.84013224,  0.61892039,  0.86199653,\n",
       "        0.51451206,  0.680884  ,  0.81326264,  0.71718049,  0.67225444,\n",
       "        0.72572905,  0.72993785,  0.61420977,  0.62723279,  0.64484966,\n",
       "        0.71101451,  0.66626954,  0.64171815,  0.61586559,  0.93474859,\n",
       "        0.89216417,  0.58520699,  0.77467453,  0.65258372,  0.77879506,\n",
       "        0.56638116,  0.63276523,  0.75172931,  0.64237159,  0.8469997 ,\n",
       "        0.61251831,  0.49196249,  0.66515315,  0.8409034 ,  0.84862882,\n",
       "        0.94470102,  0.60579449,  0.65358776,  0.56485862,  0.81260002,\n",
       "        0.86782163,  0.64572531,  0.62791502,  0.96585321,  0.62427729,\n",
       "        0.67315972,  0.6333614 ,  0.91354734,  0.60252362,  0.87390381,\n",
       "        0.58632064,  0.9544636 ,  0.88256973,  0.93538547,  0.65188462,\n",
       "        0.53127742,  0.55783683,  0.74649501,  0.57126564,  0.62370968,\n",
       "        0.59092957,  0.57990098,  0.71868002,  0.61546081,  0.75784779,\n",
       "        0.86432356,  0.62232745,  0.68493307,  0.6717245 ,  0.73616046,\n",
       "        0.61190951,  0.62005091,  0.68601114,  0.64366055,  0.65396488,\n",
       "        0.6307717 ,  0.65720588,  0.71085221,  0.64846319,  0.72575426,\n",
       "        0.7999506 ,  0.86574674,  0.62461281,  0.6043849 ,  0.64151496,\n",
       "        0.59071493,  0.62536806,  0.61092782,  0.56067181,  0.64949638,\n",
       "        0.72905487,  0.57227463,  0.62706709,  0.58174932,  0.91150421,\n",
       "        0.66230166,  0.65375048,  0.62206304,  0.62285191,  0.54422724], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.65,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.475,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.54125,\n",
       " 0.8999999999999999,\n",
       " 0.9750000000000001,\n",
       " 0.8,\n",
       " 0.42500000000000004,\n",
       " 0.575,\n",
       " 0.22499999999999998,\n",
       " 0.925,\n",
       " 0.53375,\n",
       " 0.725,\n",
       " 0.7,\n",
       " 0.07500000000000001,\n",
       " 0.8500000000000001,\n",
       " 0.8374999999999999,\n",
       " 0.65,\n",
       " 0.7749999999999999,\n",
       " 0.75,\n",
       " 0.575,\n",
       " 0.575,\n",
       " 0.35,\n",
       " 0.525,\n",
       " 0.625,\n",
       " 0.625,\n",
       " 0.625,\n",
       " 0.575,\n",
       " 0.8999999999999999,\n",
       " 0.6,\n",
       " 0.44625000000000004,\n",
       " 0.725,\n",
       " 0.725,\n",
       " 0.75,\n",
       " 0.525,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.625,\n",
       " 0.525,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.95,\n",
       " 0.275,\n",
       " 0.825,\n",
       " 0.525,\n",
       " 0.575,\n",
       " 0.0,\n",
       " 0.625,\n",
       " 0.5,\n",
       " 0.7749999999999999,\n",
       " 0.65,\n",
       " 0.825,\n",
       " 0.8999999999999999,\n",
       " 0.65,\n",
       " 0.57125,\n",
       " 0.7,\n",
       " 0.7749999999999999,\n",
       " 1.0,\n",
       " 0.125,\n",
       " 0.9750000000000001,\n",
       " 0.04999999999999999,\n",
       " 0.65,\n",
       " 0.475,\n",
       " 0.09999999999999998,\n",
       " 0.875,\n",
       " 0.175,\n",
       " 0.7,\n",
       " 0.375,\n",
       " 0.75,\n",
       " 0.9750000000000001,\n",
       " 0.9750000000000001,\n",
       " 0.575,\n",
       " 0.7,\n",
       " 0.04999999999999999,\n",
       " 0.875,\n",
       " 0.925,\n",
       " 0.8999999999999999,\n",
       " 0.025000000000000022,\n",
       " 1.0,\n",
       " 0.925,\n",
       " 0.025000000000000022,\n",
       " 0.8999999999999999,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.8999999999999999,\n",
       " 0.0,\n",
       " 0.75,\n",
       " 0.625,\n",
       " 0.8,\n",
       " 0.9750000000000001,\n",
       " 1.0,\n",
       " 0.575,\n",
       " 0.95,\n",
       " 0.55,\n",
       " 0.025000000000000022,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.95,\n",
       " 0.725,\n",
       " 0.7749999999999999,\n",
       " 0.525,\n",
       " 0.925,\n",
       " 0.875,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.575,\n",
       " 0.6,\n",
       " 0.42500000000000004,\n",
       " 0.625,\n",
       " 0.5,\n",
       " 0.925,\n",
       " 0.07500000000000001,\n",
       " 0.8500000000000001,\n",
       " 0.925,\n",
       " 0.30000000000000004,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.375,\n",
       " 0.525,\n",
       " 0.875,\n",
       " 0.8999999999999999,\n",
       " 0.95,\n",
       " 0.725,\n",
       " 0.33375,\n",
       " 0.525,\n",
       " 0.7749999999999999,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.825,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 0.42500000000000004,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 1.0,\n",
       " 0.95,\n",
       " 0.875,\n",
       " 0.42500000000000004,\n",
       " 0.42500000000000004,\n",
       " 1.0,\n",
       " 0.7,\n",
       " 0.55,\n",
       " 0.825,\n",
       " 0.75,\n",
       " 0.35,\n",
       " 0.5,\n",
       " 0.575,\n",
       " 0.95,\n",
       " 0.625,\n",
       " 0.6,\n",
       " 0.575,\n",
       " 0.32499999999999996,\n",
       " 0.55,\n",
       " 0.925,\n",
       " 0.32499999999999996,\n",
       " 0.8999999999999999,\n",
       " 0.525,\n",
       " 0.65,\n",
       " 0.44999999999999996,\n",
       " 0.7,\n",
       " 0.675,\n",
       " 0.9750000000000001,\n",
       " 0.675,\n",
       " 0.9750000000000001,\n",
       " 0.175,\n",
       " 0.275,\n",
       " 0.55,\n",
       " 0.6,\n",
       " 0.9750000000000001,\n",
       " 0.7749999999999999,\n",
       " 0.95,\n",
       " 0.55,\n",
       " 0.22499999999999998,\n",
       " 1.0,\n",
       " 0.8500000000000001,\n",
       " 0.7749999999999999,\n",
       " 0.95,\n",
       " 0.65,\n",
       " 0.575,\n",
       " 0.9750000000000001,\n",
       " 0.8999999999999999,\n",
       " 0.825,\n",
       " 0.6,\n",
       " 0.925,\n",
       " 1.0,\n",
       " 0.42500000000000004,\n",
       " 0.9750000000000001,\n",
       " 0.675,\n",
       " 0.7,\n",
       " 0.9750000000000001,\n",
       " 0.825,\n",
       " 0.55,\n",
       " 1.0,\n",
       " 0.95,\n",
       " 0.55,\n",
       " 0.6,\n",
       " 0.57125,\n",
       " 0.8500000000000001,\n",
       " 0.6,\n",
       " 0.825,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.725,\n",
       " 0.675,\n",
       " 0.30000000000000004,\n",
       " 0.825,\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.9750000000000001,\n",
       " 0.475,\n",
       " 0.875,\n",
       " 0.4,\n",
       " 0.8999999999999999,\n",
       " 0.575,\n",
       " 0.925,\n",
       " 0.725,\n",
       " 0.55,\n",
       " 0.925,\n",
       " 0.6,\n",
       " 0.675,\n",
       " 0.75,\n",
       " 0.675,\n",
       " 0.7,\n",
       " 0.65,\n",
       " 0.175,\n",
       " 0.8500000000000001,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.8999999999999999,\n",
       " 0.8500000000000001,\n",
       " 0.42500000000000004,\n",
       " 0.675,\n",
       " 0.5,\n",
       " 0.04999999999999999,\n",
       " 0.8,\n",
       " 0.65,\n",
       " 0.8500000000000001,\n",
       " 0.35,\n",
       " 0.65,\n",
       " 0.95,\n",
       " 0.8500000000000001,\n",
       " 0.95,\n",
       " 0.09999999999999998,\n",
       " 0.675,\n",
       " 0.7,\n",
       " 0.48375,\n",
       " 0.8500000000000001,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.7,\n",
       " 1.0,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.875,\n",
       " 0.675,\n",
       " 0.925,\n",
       " 0.42500000000000004,\n",
       " 1.0,\n",
       " 0.8500000000000001,\n",
       " 0.9750000000000001,\n",
       " 0.625,\n",
       " 0.65,\n",
       " 0.04999999999999999,\n",
       " 0.275,\n",
       " 0.95,\n",
       " 0.75,\n",
       " 0.0,\n",
       " 0.625,\n",
       " 1.0,\n",
       " 0.30000000000000004,\n",
       " 0.65,\n",
       " 0.825,\n",
       " 0.7749999999999999,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.675,\n",
       " 0.8,\n",
       " 0.32499999999999996,\n",
       " 1.0,\n",
       " 0.04999999999999999,\n",
       " 0.75,\n",
       " 0.675,\n",
       " 0.09999999999999998,\n",
       " 0.55,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.75,\n",
       " 0.525,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.7,\n",
       " 0.32499999999999996,\n",
       " 0.75,\n",
       " 0.675,\n",
       " 0.44999999999999996,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.575,\n",
       " 0.75,\n",
       " 0.375,\n",
       " 0.5,\n",
       " 0.15000000000000002,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.7749999999999999,\n",
       " 0.4,\n",
       " 0.575,\n",
       " 1.0,\n",
       " 0.9750000000000001,\n",
       " 0.8999999999999999,\n",
       " 0.44999999999999996,\n",
       " 0.30000000000000004,\n",
       " 0.55,\n",
       " 0.32499999999999996,\n",
       " 0.7,\n",
       " 0.625,\n",
       " 0.525,\n",
       " 0.75,\n",
       " 0.525,\n",
       " 0.575,\n",
       " 0.42500000000000004,\n",
       " 0.725,\n",
       " 0.42500000000000004,\n",
       " 0.875,\n",
       " 0.95,\n",
       " 0.44999999999999996,\n",
       " 0.9750000000000001,\n",
       " 0.625,\n",
       " 0.575,\n",
       " 0.55,\n",
       " 0.95,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.30000000000000004,\n",
       " 0.75,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.54625,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.375,\n",
       " 0.7,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.55,\n",
       " 1.0,\n",
       " 0.4,\n",
       " 1.0,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.95,\n",
       " 0.825,\n",
       " 0.7749999999999999,\n",
       " 0.575,\n",
       " 0.525,\n",
       " 0.7749999999999999,\n",
       " 0.35,\n",
       " 0.9750000000000001,\n",
       " 0.65,\n",
       " 0.625,\n",
       " 0.9750000000000001,\n",
       " 0.65,\n",
       " 0.375,\n",
       " 0.9750000000000001,\n",
       " 0.35,\n",
       " 0.5,\n",
       " 0.575,\n",
       " 0.475,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.875,\n",
       " 0.525,\n",
       " 0.65,\n",
       " 0.675,\n",
       " 0.875,\n",
       " 0.7,\n",
       " 0.475,\n",
       " 0.825,\n",
       " 0.125,\n",
       " 0.55,\n",
       " 0.725,\n",
       " 0.8500000000000001,\n",
       " 0.675,\n",
       " 0.725,\n",
       " 0.925,\n",
       " 0.25,\n",
       " 0.525,\n",
       " 0.30000000000000004,\n",
       " 0.6,\n",
       " 0.32499999999999996,\n",
       " 0.625,\n",
       " 0.44999999999999996,\n",
       " 0.95,\n",
       " 0.5,\n",
       " 0.8500000000000001,\n",
       " 0.5,\n",
       " 0.95,\n",
       " 0.8500000000000001,\n",
       " 0.35,\n",
       " 0.58375,\n",
       " 0.8,\n",
       " 0.525,\n",
       " 0.8500000000000001,\n",
       " 0.8500000000000001,\n",
       " 0.95,\n",
       " 0.8,\n",
       " 0.35,\n",
       " 0.825,\n",
       " 0.575,\n",
       " 0.75,\n",
       " 0.8999999999999999,\n",
       " 0.7749999999999999,\n",
       " 0.825,\n",
       " 0.525,\n",
       " 0.55,\n",
       " 0.8,\n",
       " 0.8500000000000001,\n",
       " 0.95,\n",
       " 0.7,\n",
       " 0.9750000000000001,\n",
       " 0.95,\n",
       " 0.75,\n",
       " 0.8999999999999999,\n",
       " 0.625,\n",
       " 0.825,\n",
       " 0.675,\n",
       " 0.875,\n",
       " 0.7,\n",
       " 0.525,\n",
       " 0.875,\n",
       " 0.75,\n",
       " 0.7,\n",
       " 0.8500000000000001,\n",
       " 0.675,\n",
       " 0.32499999999999996,\n",
       " 0.475,\n",
       " 0.65,\n",
       " 0.8500000000000001,\n",
       " 0.44999999999999996,\n",
       " 0.6,\n",
       " 0.35,\n",
       " 0.9750000000000001,\n",
       " 0.875,\n",
       " 0.675,\n",
       " 0.8500000000000001,\n",
       " 0.55,\n",
       " 0.25,\n",
       " 0.825,\n",
       " 0.75,\n",
       " 0.55,\n",
       " 0.525,\n",
       " 0.9750000000000001,\n",
       " 0.575,\n",
       " 0.8,\n",
       " 0.9750000000000001,\n",
       " 0.5,\n",
       " 0.625,\n",
       " 0.575,\n",
       " 0.7749999999999999,\n",
       " 0.75,\n",
       " 0.8500000000000001,\n",
       " 0.675,\n",
       " 0.15000000000000002,\n",
       " 0.75,\n",
       " 0.475,\n",
       " 0.44999999999999996,\n",
       " 0.875,\n",
       " 0.9750000000000001,\n",
       " 0.65,\n",
       " 0.95,\n",
       " 0.625,\n",
       " 0.8,\n",
       " 0.875,\n",
       " 0.725,\n",
       " 0.8500000000000001,\n",
       " 0.8500000000000001,\n",
       " 0.025000000000000022,\n",
       " 0.0,\n",
       " 0.09999999999999998,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.44999999999999996,\n",
       " 0.04999999999999999,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.relatedness_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
